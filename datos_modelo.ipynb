{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instaladores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- #\n",
    "# Importación de librerías  #\n",
    "# ------------------------- #\n",
    "\n",
    "# Librerías estándar para análisis de datos y cálculos matemáticos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "\n",
    "# Librerías para bases de datos\n",
    "import pyodbc\n",
    "import sqlite3\n",
    "\n",
    "# Visualización\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning y modelado\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# Estadísticas y pruebas de hipótesis\n",
    "from scipy.stats import (\n",
    "    rv_discrete, t, binom, chi2, f, \n",
    "    ttest_ind\n",
    ")\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# ------------------------- #\n",
    "# Importación de módulos    #\n",
    "# ------------------------- #\n",
    "\n",
    "# Modulo EDA\n",
    "import importlib\n",
    "import funciones_eda\n",
    "importlib.reload(funciones_eda)\n",
    "from funciones_eda import *\n",
    "\n",
    "# Módulo de funciones personalizadas\n",
    "import funciones_m\n",
    "importlib.reload(funciones_m)\n",
    "from funciones_m import *\n",
    "\n",
    "# Módulo de distribución\n",
    "import funciones_distribucion\n",
    "importlib.reload(funciones_distribucion)\n",
    "from funciones_distribucion import *\n",
    "\n",
    "# Módulo de pruebas significativas\n",
    "import funciones_pruebas_significativas\n",
    "importlib.reload(funciones_pruebas_significativas)\n",
    "from funciones_pruebas_significativas import *\n",
    "\n",
    "# Módulo de clostering\n",
    "import funciones_clostering\n",
    "importlib.reload(funciones_clostering)\n",
    "from funciones_clostering import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'df_modelo.csv'\n",
    "df = pd.read_csv(url, index_col=None)\n",
    "#df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['Semana','CUSTOMER_ID','cliente','PRODUCT_ID','producto','QTY']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### target encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target encoding es una técnica de codificación utilizada en machine learning para transformar variables categóricas en valores numéricos mediante el uso de la variable objetivo. \n",
    "Se basa en calcular el promedio o estadístico de la variable objetivo para cada categoría de la variable categórica y reemplazar dicha categoría por su valor numérico correspondiente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_target_mean = df.groupby('CUSTOMER_ID')['QTY'].mean().reset_index()\n",
    "customer_target_mean.columns = ['CUSTOMER_ID', 'customer_target_mean']\n",
    "df = df.merge(customer_target_mean, on='CUSTOMER_ID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "producto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_target_mean = df.groupby('PRODUCT_ID')['QTY'].mean().reset_index()\n",
    "product_target_mean.columns = ['PRODUCT_ID', 'product_target_mean']\n",
    "df = df.merge(product_target_mean, on='PRODUCT_ID', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### crear variable  target categorica se_compra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model=df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se organiza dataframe en el orden cliente, producto y semana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model=df_model.sort_values(by=['CUSTOMER_ID','PRODUCT_ID','Semana'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n términos generales, esta línea de código crea una nueva columna que contiene el valor de la siguiente fila dentro de cada grupo definido por las columnas CUSTOMER_ID y PRODUCT_ID.\n",
    "\n",
    "El objetivo es \"desplazar\" los valores de una columna ( QTYen este caso) hacia arriba dentro de un grupo, lo que permite relacionar el valor actual con el siguiente valor temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model['QTY_next_week'] = df_model.groupby(['CUSTOMER_ID', 'PRODUCT_ID'])['QTY'].shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Este código crea una nueva columna en el DataFrame llamada QTY_next_week, que contiene el valor de QTY de la semana siguiente para el mismo cliente (CUSTOMER_ID) y el mismo producto (PRODUCT_ID). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model['Semana_next'] = df_model.groupby(['CUSTOMER_ID', 'PRODUCT_ID'])['Semana'].shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**se crea la variable de compra proxima semana**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model['se_compra'] = ((df_model['Semana_next'] == df_model['Semana'] + 1) & \n",
    "                         (df_model['QTY_next_week'] > 0)).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se filtra data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_=df_model[['customer_target_mean','product_target_mean','Semana','QTY','se_compra']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model_ = df_model_.rename(columns={\n",
    "    'customer_target_mean': 'target_cliente',\n",
    "    'product_target_mean': 'target_producto',\n",
    "    'QTY': 'cantidad',\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datos de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "se está seleccionando el 90 % del DataFrame y dejando las restantes, por lo que la división no es aleatoria sino secuencial y dejando el 10% para prueba del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_first_part = 0.90\n",
    "\n",
    "# sacamos el porcentaje de datos de la primera parte\n",
    "n_rows_part_1= int(len(df_model_)*percentage_first_part)\n",
    "\n",
    "# sacamos el 90% de los datos aleatorios \n",
    "df_ = df_model_.iloc[:n_rows_part_1].reset_index(drop=True)\n",
    "df_p=df_model_.iloc[n_rows_part_1:].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18699"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Valores atípicos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear un objeto LocalOutlierFactor con n_neighbors=13\n",
    "lof = LocalOutlierFactor(n_neighbors=13, contamination=0.1)\n",
    "y_pred = lof.fit_predict(df_[['cantidad']])\n",
    "\n",
    "# Identificar los índices de los valores atípicos\n",
    "outliers = y_pred == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices de valores atípicos:  [350, 1563, 2777, 4628, 5363, 5671, 6169, 6459, 6622, 8408, 8548, 8936, 9078, 9290, 9291, 9855, 10481, 10777, 11849, 12020, 12050, 12070, 12315, 13158, 13714, 13719, 13761, 13842, 14661, 16266, 17793, 17797]\n"
     ]
    }
   ],
   "source": [
    "print('Indices de valores atípicos: ', df_[outliers].index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar los valores atípicos del dataframe original\n",
    "df_=df_.loc[~outliers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oversampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea un objeto RandomOverSampler que permite crear copias aleatorias de las muestras de la clase \n",
    "# minoritaria para igualar el número de muestras entre las diferentes clases.\n",
    "oversampler = RandomOverSampler()\n",
    "\n",
    "# Se realiza el sobremuestreo para las variables de entrada y salida\n",
    "X_resampled, y_resampled = oversampler.fit_resample(df_.drop('se_compra', axis=1), df_['se_compra'])\n",
    "\n",
    "# Se crean dos dataframes con las variables de entrada y otro con la variable de salida a partir del proceso anterior\n",
    "df_1 = pd.DataFrame(X_resampled, columns=df_.columns.drop('se_compra'))\n",
    "df_2 = pd.DataFrame(y_resampled)\n",
    "\n",
    "# Se concatenan los dataframes horizontalmente\n",
    "df__balanced = pd.concat([df_1, df_2], axis=1)\n",
    "\n",
    "df_=df__balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.to_csv('df_ML.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
